# LiteLLM Configuration
# You can use any LLM provider supported by LiteLLM
# Examples: openai, anthropic, azure, cohere, huggingface, etc.

# OpenAI (default)
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-3.5-turbo

# Alternative: Anthropic Claude
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# LLM_MODEL=claude-3-haiku-20240307

# Alternative: Local models via Ollama
# LLM_MODEL=ollama/llama2
# OLLAMA_API_BASE=http://localhost:11434

# Alternative: Azure OpenAI
# AZURE_API_KEY=your_azure_api_key_here
# AZURE_API_BASE=your_azure_endpoint_here
# AZURE_API_VERSION=2023-05-15
# LLM_MODEL=azure/gpt-35-turbo

# Vector Store Configuration
CHROMA_PERSIST_DIRECTORY=./data/chroma_db
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# PDF Data Directory
PDF_DIRECTORY=./data/pdfs

# Session Configuration
SESSION_TIMEOUT=3600
MAX_CHAT_HISTORY=20

# Flask Configuration
FLASK_SECRET_KEY=your_secret_key_here
FLASK_DEBUG=True
FLASK_PORT=5000
